{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d709ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import TOFPET_cal_lib as TPcal\n",
    "from scipy import interpolate\n",
    "import time\n",
    "import build_data_df_mine as bd\n",
    "\n",
    "\n",
    "%matplotlib nbagg\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164cc19b",
   "metadata": {},
   "source": [
    "run = 10935\n",
    "file_number = 0\n",
    "calib_file = 10932"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf967c0",
   "metadata": {},
   "source": [
    "# Calibration INFO\n",
    "path_cal = \"/home/vherrero/CALIBRATION_FILES/\"\n",
    "asic0_efine_cal = \"asic0_efine_cal_poly_run\"+str(calib_file)+\".h5\" #10932\n",
    "asic0_tfine_cal = \"asic0_tfine_cal.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f65f34",
   "metadata": {},
   "source": [
    "# Output file\n",
    "output_file = \"/home/vherrero/PROCESSED_FILES/\" + \"asic0_run\" + str(run) + \"_file\" \\\n",
    "              + str(file_number) + \"_beta.h5\"\n",
    "\n",
    "print(\"\\nLoading Calibration Data \\n\")\n",
    "coeffs_qdc = pd.read_hdf(path_cal + asic0_efine_cal, key='efine')\n",
    "coeffs_tdc = pd.read_hdf(path_cal + asic0_tfine_cal, key='tfine_cal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46abfc2",
   "metadata": {},
   "source": [
    "# Reads run data\n",
    "print(\"Loading Run Data \\n\")\n",
    "data   = pd.read_hdf('/analysis/' + str(run) + '/hdf5/data/run_' + str(run) +\\\n",
    "                     '_'+ str(file_number).zfill(4) + '_trigger1_waveforms.h5',\n",
    "                     key='data'),\n",
    "                     #start=0,stop=25000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d00bc5",
   "metadata": {},
   "source": [
    "# Integration Window computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07675785",
   "metadata": {},
   "source": [
    "print(\"Generating Intg_w column \\n\")\n",
    "bd.compute_integration_window_size(data)\n",
    "data['intg_w'] = data['intg_w'] - 5.0\n",
    "# Life is NOT wonderful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a4c2e",
   "metadata": {},
   "source": [
    "# Tfine and Efine preprocessing (see TOFPET datasheet for wraparound explanation)\n",
    "data['tfine'] = (data['tfine'] - 1024 + 14) % 1024\n",
    "data['efine'] = (data['efine'] - 1024 + 14) % 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c96494",
   "metadata": {},
   "source": [
    "# Applies QDC & TDC calibration correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f4cd2",
   "metadata": {},
   "source": [
    "print(\"Applying TDC correction \\n\")\n",
    "data = bd.apply_tdc_correction(data,coeffs_tdc)\n",
    "print(\"Applying QDC correction \\n\")\n",
    "data = bd.apply_qdc_bm_correction(data,coeffs_qdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e3491",
   "metadata": {},
   "source": [
    "# Extended TCOARSE computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0d96c",
   "metadata": {},
   "source": [
    "data['tcoarse']      = data.tcoarse.astype(np.int32)\n",
    "data['tcoarse_diff'] = data.tcoarse.diff()\n",
    "data['nloops']       = bd.compute_tcoarse_nloops_per_event(data)\n",
    "data['tcoarse_extended'] = bd.compute_extended_tcoarse(data)\n",
    "data.drop(columns=['tcoarse_diff','nloops'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62a50b",
   "metadata": {},
   "source": [
    "# Find Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ecc79",
   "metadata": {},
   "source": [
    "print(\"Finding Clusters \\n\")\n",
    "bd.compute_evt_number_combined_with_cluster_id(data)\n",
    "nuniq = data.groupby(['cluster'])['sensor_id'].nunique().rename('n_sipms')\n",
    "clustered_df = data.join(nuniq, on='cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c21ccd",
   "metadata": {},
   "source": [
    "# Write output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b02382",
   "metadata": {},
   "source": [
    "print(\"Writing output data \\n\")\n",
    "print(data)\n",
    "\n",
    "with pd.HDFStore(output_file,'w',complib=\"zlib\",complevel=4) as storage:\n",
    "    storage.put('data',clustered_df,index=False,format='table',data_columns=None)\n",
    "    storage.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c28e89",
   "metadata": {},
   "source": [
    "# ------------------ DATA PLOTS -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4322748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [10939,10940]\n",
    "file_numbers = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = file_numbers[0]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in runs:\n",
    "    data_aux=[]\n",
    "    file_data = '/analysis/' + str(i) + '/hdf5/proc/LED/files/run_' + str(i) +\\\n",
    "                 '_'+ str(file_number).zfill(4) + '_trigger1_waveforms.h5'\n",
    "    \n",
    "    with pd.HDFStore(file_data,'r',complib=\"zlib\",complevel=4) as storage:\n",
    "        for j in storage.keys():\n",
    "            data_aux.append(pd.read_hdf(file_data,j))\n",
    "\n",
    "    data.append(pd.concat(data_aux).reset_index())\n",
    "        #data = np.concatenate((data,data_aux['efine_corrected'].to_numpy()),axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1ac30",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [31,  5, 11, 26]\n",
    "sipm     = [44, 45, 18, 11]\n",
    "\n",
    "data_plot_1 = data[0][(data[0]['efine']>50) & (data[0]['efine']<300) & (data[0]['channel_id']==31)]\n",
    "data_plot_4 = data[1][(data[1]['efine']>50) & (data[1]['efine']<300) & (data[1]['channel_id']==31)]\n",
    "data_plot_2 = data_plot_4['channel_id']\n",
    "data_plot_3 = data_plot_4['intg_w']\n",
    "print(np.mean(data_plot_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ca554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "#plt.hist(data,bins=1024,density=1,range=[-100,1024])\n",
    "axis = fig.add_subplot(221)\n",
    "TPcal.gauss_fit(data_plot_1['efine'],150,True,axis,'','','Channel run N',[0.65,0.5,\"left\"])\n",
    "axis = fig.add_subplot(222)\n",
    "TPcal.gauss_fit(data_plot_2,150,True,axis,'','','Channel ID',[0.65,0.5,\"left\"])\n",
    "axis = fig.add_subplot(223)\n",
    "TPcal.gauss_fit(data_plot_3,150,True,axis,'','','Integration Window',[0.65,0.5,\"left\"])\n",
    "axis = fig.add_subplot(224)\n",
    "TPcal.gauss_fit(data_plot_4['efine'],150,True,axis,'','','Channel run N-1',[0.65,0.5,\"left\"])\n",
    "#clustered_df['efine_corrected'].hist(bins=100,range=(-20,100)) #,log='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcaf6fc",
   "metadata": {},
   "source": [
    "## Compute event energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_array_h = []\n",
    "sipm_array   = []\n",
    "\n",
    "for i in clustered_df['cluster'].unique():\n",
    "    if i != -1:\n",
    "        evt = clustered_df[clustered_df['cluster']==i]\n",
    "        #print(evt['tofpet_id'].unique())\n",
    "        \n",
    "        #Rough coincidence filter\n",
    "        if evt['tofpet_id'].unique().size == 2:\n",
    "            hamamatsu = evt[evt['tofpet_id']==0]\n",
    "            energy_hamamatsu = np.sum(hamamatsu['efine_corrected'])\n",
    "            energy_array_h.append(energy_hamamatsu)\n",
    "            #sipm_array.append(evt['n_sipms'].unique()[0])\n",
    "energy_array_h = np.array(energy_array_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[5,5])\n",
    "\n",
    "#energy_array = energy_array[(energy_array>-100) & (energy_array<300)]\n",
    "\n",
    "\n",
    "axis = fig.add_subplot(111)\n",
    "coeff,coeff_err,chisq_r=TPcal.gauss_fit(energy_array_h,250,True,axis,'Gauss Fit','','',[0.65,0.5,\"left\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
